{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1119, 0.1021, 0.1026, 0.1123, 0.1156, 0.1169, 0.1072, 0.1223, 0.1089]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# implementing a simple policy network for tic tac toe that outputs a probability distribution over all moves\n",
    "\n",
    "class SimplePolicyNetwork(nn.Module):\n",
    "    def __init__(self, board_size, num_moves):\n",
    "        \"\"\"\n",
    "        Initializes the Policy Network.\n",
    "        :param board_size: Tuple of the board dimensions, e.g., (19, 19) for Go.\n",
    "        :param num_moves: Total number of possible moves in the game.\n",
    "        \"\"\"\n",
    "        super(SimplePolicyNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(128 * board_size[0] * board_size[1], num_moves)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "        :param x: Input tensor, the game state.\n",
    "        :return: Probability distribution over all possible moves.\n",
    "        \"\"\"\n",
    "        # Apply two convolutional layers with ReLU activations\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        # Flatten the output for the fully connected layer\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Output layer with a softmax to get probabilities\n",
    "        x = self.fc(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "# Example usage\n",
    "board_size = (3, 3)  # For Tic Tac Toe\n",
    "num_moves = board_size[0] * board_size[1]  # Assuming each cell is a possible move\n",
    "model = SimplePolicyNetwork(board_size, num_moves)\n",
    "\n",
    "# Example input: a single game state, with 1 channel, and 19x19 board size\n",
    "# The input should be a 4D tensor: [batch_size, channels, height, width]\n",
    "# Here, batch_size = 1, channels = 1 (just the board, could be more for different game states)\n",
    "game_state = torch.randn(1, 1, board_size[0], board_size[1])\n",
    "# Get the probability distribution over moves\n",
    "probabilities = model(game_state)\n",
    "\n",
    "print(probabilities)  # Each element corresponds to the probability of a move being the best next move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving tic-tac-toe using tree search\n",
    "# This is a simple implementation of the minimax algorithm\n",
    "\n",
    "# The game is represented as a 3x3 matrix\n",
    "# 0 represents an empty cell\n",
    "# 1 represents a cell with a cross\n",
    "# 2 represents a cell with a circle\n",
    "\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.turn = 1\n",
    "        self.winner = 0\n",
    "\n",
    "    def is_full(self):\n",
    "        return np.all(self.board)\n",
    "\n",
    "    def is_winner(self, player):\n",
    "        for i in range(3):\n",
    "            if np.all(self.board[i] == player) or np.all(self.board[:, i] == player):\n",
    "                return True\n",
    "        if np.all(self.board.diagonal() == player) or np.all(np.fliplr(self.board).diagonal() == player):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_game_over(self):\n",
    "        for player in [1, 2]:\n",
    "            if self.is_winner(player):\n",
    "                self.winner = player\n",
    "                return True\n",
    "        return self.is_full()\n",
    "\n",
    "    def get_valid_moves(self):\n",
    "        return np.argwhere(self.board == 0)\n",
    "    \n",
    "    def get_valid_moves_indices(self):\n",
    "        return np.flatnonzero(self.board == 0)\n",
    "    \n",
    "\n",
    "    def make_move(self, move):\n",
    "        self.board[tuple(move)] = self.turn\n",
    "        self.turn = 3 - self.turn\n",
    "\n",
    "    def make_move_from_index(self, index):\n",
    "        move = np.unravel_index(index, (3, 3))\n",
    "        self.make_move(move)\n",
    "\n",
    "    def undo_move(self, move):\n",
    "        self.board[tuple(move)] = 0\n",
    "        self.turn = 3 - self.turn\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game = TicTacToe()\n",
    "# game.make_move((1,1))\n",
    "# print(game)\n",
    "\n",
    "# game.make_move((2,1))\n",
    "# print(game)\n",
    "\n",
    "# game.make_move((0,1))\n",
    "# print(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "------\n",
      "[[0 1 0]\n",
      " [0 2 0]\n",
      " [0 0 0]]\n",
      "------\n",
      "[[0 1 0]\n",
      " [0 2 0]\n",
      " [0 1 0]]\n",
      "------\n",
      "[[2 1 0]\n",
      " [0 2 0]\n",
      " [0 1 0]]\n",
      "------\n",
      "[[2 1 0]\n",
      " [0 2 0]\n",
      " [0 1 1]]\n",
      "------\n",
      "[[2 1 0]\n",
      " [0 2 2]\n",
      " [0 1 1]]\n",
      "------\n",
      "[[2 1 0]\n",
      " [0 2 2]\n",
      " [1 1 1]]\n",
      "------\n",
      "Player 1 wins!\n"
     ]
    }
   ],
   "source": [
    "def convert_board_to_input(board):\n",
    "    \"\"\"\n",
    "    Convert the game board to a tensor suitable for the policy network.\n",
    "    The input is a 4D tensor: [batch_size, channels, height, width].\n",
    "    \"\"\"\n",
    "    # Convert the board to a tensor with shape (1, 1, 3, 3)\n",
    "    # 1 channel, the board's state is represented in a 3x3 grid\n",
    "    board_tensor = torch.tensor(board, dtype=torch.float).unsqueeze(0).unsqueeze(0)\n",
    "    return board_tensor\n",
    "\n",
    "def select_move(probabilities, valid_moves_indices):\n",
    "    \"\"\"\n",
    "    Select the move with the highest probability that is also a valid move.\n",
    "    \"\"\"\n",
    "    # Zero out the probabilities of moves that are not valid\n",
    "    prob_masked = probabilities.clone().detach()\n",
    "    prob_masked[0, np.setdiff1d(np.arange(num_moves), valid_moves_indices)] = 0\n",
    "    # Select the move with the highest probability\n",
    "    move_index = torch.argmax(prob_masked).item()\n",
    "    return move_index\n",
    "\n",
    "# Initialize the TicTacToe game\n",
    "game = TicTacToe()\n",
    "\n",
    "# Initialize the policy network\n",
    "model = SimplePolicyNetwork(board_size, num_moves)\n",
    "\n",
    "# Play until the game is over\n",
    "while not game.is_game_over():\n",
    "    # Convert the current game state to a tensor input for the network\n",
    "    current_state_tensor = convert_board_to_input(game.board)\n",
    "    # Get the probability distribution over moves from the policy network\n",
    "    probabilities = model(current_state_tensor)\n",
    "    # Get valid move indices\n",
    "    valid_moves_indices = game.get_valid_moves_indices()\n",
    "    # Select the move with the highest probability among valid moves\n",
    "    selected_move_index = select_move(probabilities, valid_moves_indices)\n",
    "    # Make the move\n",
    "    game.make_move_from_index(selected_move_index)\n",
    "    # Print the board state\n",
    "    print(game)\n",
    "    print(\"------\")\n",
    "\n",
    "# Check the result\n",
    "if game.winner:\n",
    "    print(f\"Player {game.winner} wins!\")\n",
    "else:\n",
    "    print(\"It's a draw!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (973205156.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [4], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
